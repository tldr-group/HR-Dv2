{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fbdb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tifffile import imread\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import label2rgb\n",
    "from skimage.transform import resize\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from hr_dv2.wss.featurisers import get_featuriser_classifier\n",
    "from hr_dv2.wss.train import Classifiers, get_classifier, train_model, apply_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a465f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path: str) -> Image.Image:\n",
    "    extension = image_path.split('.')[-1].lower()\n",
    "    if extension in ['jpg', 'jpeg', 'png']:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    elif extension in ['tiff', 'tif']:\n",
    "        image_arr = imread(image_path)\n",
    "        image = Image.fromarray(image_arr)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported image format: {extension}\")\n",
    "    return image\n",
    "\n",
    "def tiff_to_labels(tiff: np.ndarray, rev: bool=False) -> np.ndarray:\n",
    "    if tiff.shape[0] == 1:\n",
    "        tiff = tiff[0]\n",
    "    out = tiff\n",
    "    vals = np.unique(tiff)[::-1] if rev else np.unique(tiff)\n",
    "    for i, val in enumerate(vals):\n",
    "        out = np.where(tiff == val, i, out)\n",
    "    return out\n",
    "\n",
    "def resize_longest_side(img: Image.Image, l: int, patch_size: int = 14) -> Image.Image:\n",
    "    oldh, oldw = img.height, img.width\n",
    "    scale = l * 1.0 / max(oldh, oldw)\n",
    "    newh, neww = oldh * scale, oldw * scale\n",
    "    neww = int(neww + 0.5)\n",
    "    newh = int(newh + 0.5)\n",
    "    neww = neww - (neww % patch_size)\n",
    "    newh = newh - (newh % patch_size)\n",
    "\n",
    "    return img.resize((neww, newh))\n",
    "\n",
    "\n",
    "def resize_longest_side_arr(arr: np.ndarray, l: int, patch_size: int = 14) -> Image.Image:\n",
    "    oldh, oldw = arr.shape[:2]\n",
    "    scale = l * 1.0 / max(oldh, oldw)\n",
    "    newh, neww = oldh * scale, oldw * scale\n",
    "    neww = int(neww + 0.5)\n",
    "    newh = int(newh + 0.5)\n",
    "    neww = neww - (neww % patch_size)\n",
    "    newh = newh - (newh % patch_size)\n",
    "\n",
    "    return resize(arr, (newh, neww), order=0, anti_aliasing=False, clip=True, preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4017808",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = [\"nickel_superalloy\"]\n",
    "\n",
    "images = [load_image(f\"data/wss/{folder_name}/image.png\") for folder_name in folder_names]\n",
    "images = [resize_longest_side(im, 518) for im in images]\n",
    "labels = [tiff_to_labels(imread(f\"data/wss/{folder_name}/labels.tiff\")) for folder_name in folder_names]\n",
    "labels = [resize_longest_side_arr(label, 518) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67990cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurisers = [\"weka\", \"FeatUp\", \"hybrid\"]\n",
    "classifiers: list[Classifiers] = ['linear', 'logistic', 'rf', 'mlp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a89fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "all_results = {}\n",
    "for i, (img, label) in enumerate(zip(images, labels)):\n",
    "    img_name = folder_names[i]\n",
    "    print(f\"Processing {img_name}\")\n",
    "    all_results[img_name] = {}\n",
    "\n",
    "    for featuriser in featurisers:\n",
    "        all_results[img_name][featuriser] = {}\n",
    "        print(f\"Featuriser: {featuriser}\")\n",
    "        for classifier_name in classifiers:\n",
    "            classifier = get_classifier(classifier_name)\n",
    "            trs = \"both\" if featuriser in (\"hybrid\", \"DINOv2-S-14\") else None\n",
    "            model = get_featuriser_classifier(featuriser, None, None, trs)\n",
    "            \n",
    "            image_arr = np.array(img)\n",
    "            label_arr = np.array(label)\n",
    "            features = model.img_to_features(img)\n",
    "            # Train the model\n",
    "            classifier = train_model(classifier, [features], [label])\n",
    "            \n",
    "            # Apply the model to the image\n",
    "            predictions = apply_model(classifier, features)\n",
    "\n",
    "            all_results[img_name][featuriser][classifier_name] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "99c89570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "def add_inset_zoom(xywh: list[int], fig_xywh: list[float], img_arr: np.ndarray, labels: np.ndarray | None, ax ) -> object:\n",
    "    x0, y0, w, h = xywh\n",
    "    H, W, C = img_arr.shape\n",
    "    inset_data = np.zeros_like(img_arr)\n",
    "    inset_data[y0:y0+h, x0:x0+w, :] = img_arr[y0:y0+h, x0:x0+w, :]\n",
    "\n",
    "    # axin = ax.inset_axes(\n",
    "    #     fig_xywh, xlim=(x0, x0+w), ylim=(y0, y0+h), zorder=10)\n",
    "    axin = inset_axes(ax, width=\"35%\", height=\"35%\", bbox_transform=ax.transAxes, bbox_to_anchor=(0, 0, 1.15, 1) ) \n",
    "    axin.set_xticks([])\n",
    "    axin.set_yticks([])\n",
    "    if labels is not None:\n",
    "        inset_data = label2rgb(labels, img_arr, COLORS[1:], kind='overlay', alpha=1, bg_label=-1)\n",
    "        axin.imshow(inset_data)\n",
    "    else:\n",
    "        axin.imshow(inset_data, cmap=\"binary_r\",) # cmap=\"binary_r\"\n",
    "    # ax.indicate_inset_zoom(axin, edgecolor=\"black\", lw=2)\n",
    "    axin.set_xlim((x0, x0 + w))\n",
    "    axin.set_ylim((y0, y0 + h))\n",
    "    mark_inset(ax, axin, loc1=2, loc2=4, fc=\"none\", ec=\"black\", lw=2)\n",
    "    \n",
    "\n",
    "    axin.patch.set_edgecolor('black')  \n",
    "\n",
    "    axin.patch.set_linewidth(4)  \n",
    "\n",
    "    return axin\n",
    "\n",
    "def add_labels_overlay(img: Image.Image, labels: np.ndarray, colors: np.ndarray, alpha: float=0.5) -> np.ndarray:\n",
    "    img_arr = np.array(img)\n",
    "    overlay = label2rgb(labels, img_arr, colors, kind='overlay', alpha=1, bg_label=0)\n",
    "    out_arr = img_arr.copy()\n",
    "    labels_padded = np.expand_dims(labels, -1)\n",
    "    out_arr = np.where(labels_padded == 0, img_arr / 255.0, overlay)\n",
    "    return out_arr\n",
    "\n",
    "def centre_crop(img_or_arr: np.ndarray |  Image.Image, cw: int, ch: int) -> np.ndarray | Image.Image:\n",
    "    if type(img_or_arr) == np.ndarray:\n",
    "        arr: np.ndarray = img_or_arr #type:ignore\n",
    "        ih, iw = arr.shape\n",
    "        oy, ox = (ih - ch) // 2, (iw - cw) // 2\n",
    "        cropped = arr[oy:oy+ch, ox:ox+cw]\n",
    "        return cropped\n",
    "    else:\n",
    "        img: Image.Image = img_or_arr #type: ignore\n",
    "        ih, iw = img.height, img.width\n",
    "        oy, ox = (ih - ch) // 2, (iw - cw) // 2\n",
    "        bbox = (ox, oy, ox + cw, oy + ch)\n",
    "        return img.crop(bbox)\n",
    "\n",
    "def swap_label_vals(arr: np.ndarray, val_0: int, val_1: int, swap_val: int = 100) -> np.ndarray:\n",
    "    tmp = np.where(arr == val_0, swap_val, arr)\n",
    "    tmp = np.where(arr == val_1, val_0, tmp)\n",
    "    tmp = np.where(arr == swap_val, val_1, tmp)\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3290347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = [\n",
    "            \"#fafafa\",\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "        ]\n",
    "color_list = [[255, 255, 255], [31, 119, 180], [255, 127, 14], [44, 160, 44], [255, 0, 0]]\n",
    "COLORS = np.array(color_list) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9542cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "TITLE_FS = 24\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "N_ROWS = len(featurisers) + 1\n",
    "N_EXAMPLES = len(classifiers)\n",
    "N_COLS = N_EXAMPLES\n",
    "\n",
    "data_coords = [10, 410, 75, 75]\n",
    "fig_coords = [0.75, -0.05, 0.35, 0.35]\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=N_ROWS, ncols=N_COLS, figsize=(N_COLS * 4.5, N_ROWS * 4.5))\n",
    "fig = plt.figure(figsize=(N_COLS * 4, N_ROWS * 4))\n",
    "\n",
    "gs = gridspec.GridSpec(4, 4, height_ratios=[1.15, 1, 1, 1])\n",
    "\n",
    "img_ax = fig.add_subplot(gs[0, 1:3])\n",
    "img_with_labels = add_labels_overlay(img, label, COLORS[1:], alpha=0.2)\n",
    "img_ax.imshow(img_with_labels)\n",
    "img_ax.set_title(\"Image + labels\", fontsize=TITLE_FS)\n",
    "img_ax.set_xticks([])\n",
    "img_ax.set_yticks([])\n",
    "\n",
    "add_inset_zoom(data_coords, fig_coords, img_with_labels, None, img_ax)  \n",
    "\n",
    "\n",
    "col_titles = [\"Ridge\", \"Logistic\", \"Random Forest\", \"MLP\"]\n",
    "row_titles = [\"Classical\", \"Ours (DINOv2-S-14)\", \"Ours (Hybrid)\"]\n",
    "\n",
    "img_name = folder_names[0]\n",
    "for i, featuriser in enumerate(featurisers):\n",
    "    for j, classifier in enumerate(classifiers):\n",
    "        ax = fig.add_subplot(gs[i + 1, j]) \n",
    "        # ax = axs[i, j]\n",
    "        if i == 0:\n",
    "            ax.set_title(col_titles[j], fontsize=TITLE_FS)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(row_titles[i], fontsize=TITLE_FS)\n",
    "        pred = all_results[img_name][featuriser][classifier]\n",
    "\n",
    "        img_with_labels = add_labels_overlay(img, pred, COLORS[1:], alpha=0.2)\n",
    "        add_inset_zoom(data_coords, fig_coords, img_with_labels, None, ax)  \n",
    "\n",
    "        ax.imshow(img_with_labels)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../fig_out/wss_classifier_ablation.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc885aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ab6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
