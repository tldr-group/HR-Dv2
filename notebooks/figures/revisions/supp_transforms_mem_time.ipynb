{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da280475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "torch.cuda.empty_cache()\n",
    "from torch.nn.functional import interpolate\n",
    "\n",
    "from hr_dv2 import HighResDV2\n",
    "import hr_dv2.transform as tr\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time_ns\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "use_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb17993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path: str, l: int) -> tuple[torch.Tensor, np.ndarray]:\n",
    "    temp_img = Image.open(path)\n",
    "    h, w = temp_img.height, temp_img.width\n",
    "    #transform = tr.closest_crop(h, w) #tr.get_input_transform(L, L)\n",
    "    transform = tr.get_input_transform(l, l)\n",
    "    tensor, img = tr.load_image(path, transform)\n",
    "    H, W = img.height, img.width\n",
    "    return tensor, np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656e7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_mem_time(inp: torch.Tensor, model: nn.Module, seq: bool = False) -> tuple[float, float]:\n",
    "    if type(model) == HighResDV2:\n",
    "        inp = inp.squeeze(0)\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats() # s.t memory is accurate\n",
    "    torch.cuda.synchronize() # s.t time is accurate\n",
    "    def _to_MB(x: int) -> float:\n",
    "        return x / (1024**2)\n",
    "\n",
    "    def _to_s(t: int) -> float:\n",
    "        return t / 1e9\n",
    "\n",
    "    start_m = torch.cuda.max_memory_allocated()\n",
    "    start_t = time_ns()\n",
    "    \n",
    "    if seq:\n",
    "        model.forward_sequential(inp)\n",
    "    else:\n",
    "        model.forward(inp)\n",
    "\n",
    "    end_m = torch.cuda.max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    end_t = time_ns()\n",
    "\n",
    "    return _to_MB(end_m - start_m), _to_s(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8a7dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "net = HighResDV2(\"dinov2_vits14_reg\", 4, dtype=torch.float16) #dino_vits8 #dinov2_vits14_reg\n",
    "net.interpolation_mode = 'nearest-exact'\n",
    "net.eval()\n",
    "net.cuda()\n",
    "net.half()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46950e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor, img_arr = load_img('fig_data/1.jpg', (350, 350))\n",
    "img_tensor = img_tensor.cuda().unsqueeze(0)\n",
    "img_tensor = img_tensor.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4669d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    net.forward(img_tensor.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1588e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH\n",
      "\n",
      "\tno_trs, N_t=0: 281.82 MB, 0.03 s\n",
      "\tmoore_1, N_t=9: 551.13 MB, 0.21 s\n",
      "\tneumann_1, N_t=5: 505.99 MB, 0.12 s\n",
      "\tmoore_2, N_t=17: 1002.24 MB, 0.42 s\n",
      "\tmoore_2_flip, N_t=68: 4008.97 MB, 1.54 s\n",
      "\tmoore_4, N_t=33: 1945.37 MB, 0.76 s\n",
      "\tmoore_4_flip, N_t=132: 7781.51 MB, 3.03 s\n",
      "SEQUENTIAL\n",
      "\n",
      "\tno_trs, N_t=1: 281.82 MB, 0.03 s\n",
      "\tmoore_1, N_t=9: 466.34 MB, 0.26 s\n",
      "\tneumann_1, N_t=5: 464.44 MB, 0.14 s\n",
      "\tmoore_2, N_t=17: 472.56 MB, 0.49 s\n",
      "\tmoore_2_flip, N_t=68: 508.56 MB, 1.96 s\n",
      "\tmoore_4, N_t=33: 483.70 MB, 0.95 s\n",
      "\tmoore_4_flip, N_t=132: 553.09 MB, 3.81 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flip = tr.get_flip_transforms()\n",
    "no_trs = ([], [])\n",
    "moore_1 = tr.get_shift_transforms([1], 'Moore')\n",
    "neumann_1 = tr.get_shift_transforms([1], 'Neumann')\n",
    "moore_2 = tr.get_shift_transforms([1, 2], 'Moore')\n",
    "moore_4 = tr.get_shift_transforms([1, 2, 3, 4], 'Moore')\n",
    "\n",
    "moore_2_flip = tr.combine_transforms(moore_2[0], flip[0], moore_2[1], flip[1])\n",
    "moore_4_flip = tr.combine_transforms(moore_4[0], flip[0], moore_4[1], flip[1])\n",
    "\n",
    "\n",
    "names = ['no_trs', 'moore_1', 'neumann_1' , 'moore_2', 'moore_2_flip', 'moore_4', 'moore_4_flip']\n",
    "fwd_inv_transforms: list[tuple[tr.PartialTrs, tr.PartialTrs]] = [no_trs, moore_1, neumann_1, moore_2, moore_2_flip, moore_4, moore_4_flip]\n",
    "\n",
    "for is_seq in (False, True):\n",
    "    prefix = \"Sequential\" if is_seq else \"Batch\"\n",
    "    print(f\"{prefix.upper()}\\n\")\n",
    "    for i, (fwd, inv) in enumerate(fwd_inv_transforms):\n",
    "        n_t = len(fwd)\n",
    "        net.set_transforms(fwd, inv)\n",
    "        mem, time = measure_mem_time(img_tensor, net, is_seq)\n",
    "        print(f\"\\t{names[i]}, N_t={n_t}: {mem:.2f} MB, {time:.2f} s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
