{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: compare MSE of (rescaled) features of small (~200x200) test image(s) across different upsampling methods to Hy-Dv2. These methods will be: bicubic upsampling of original Dv2, bicubic upsampling of VE, blurring of nearest upsampling of VE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(0)\n",
    "from torch.nn.functional import interpolate\n",
    "\n",
    "\n",
    "from hr_dv2 import HighResDV2, torch_pca\n",
    "import hr_dv2.transform as tr\n",
    "from hr_dv2.utils import *\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from featup.util import norm, unnorm\n",
    "use_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path: str) -> tuple[torch.Tensor, np.ndarray]:\n",
    "    temp_img = Image.open(path)\n",
    "    h, w = temp_img.height, temp_img.width\n",
    "    transform = tr.closest_crop(h, w, patch_size=14)\n",
    "    tensor, img = tr.load_image(path, transform)\n",
    "    H, W = img.height, img.width\n",
    "    return tensor, np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strides = [8, 4, 1, 4]\n",
    "resizes = ['bilinear', 'nearest-exact', 'featup', 'nearest-exact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitchen: bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 364, 490])\n",
      "kitchen: nearest-exact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 364, 490])\n",
      "kitchen: featup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/mhamilton723_FeatUp_main\n",
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/featup-0.1.2-py3.10-linux-x86_64.egg/featup/featurizers/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/featup-0.1.2-py3.10-linux-x86_64.egg/featup/featurizers/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/featup-0.1.2-py3.10-linux-x86_64.egg/featup/featurizers/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 364, 490])\n",
      "kitchen: nearest-exact\n",
      "torch.Size([1, 384, 364, 490])\n",
      "train: bilinear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 322, 490])\n",
      "train: nearest-exact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 322, 490])\n",
      "train: featup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/mhamilton723_FeatUp_main\n",
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 322, 490])\n",
      "train: nearest-exact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 322, 490])\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "img_paths = [\"kitchen\", \"train\"]\n",
    "for img_path in img_paths:\n",
    "    \n",
    "    for i, method in enumerate(resizes):\n",
    "        torch.cuda.empty_cache()\n",
    "        fname = f\"fig_data/{img_path}.jpg\"\n",
    "        tensor, img_arr = load_img(fname)\n",
    "        H, W, C = img_arr.shape\n",
    "        tensor = tensor.cuda()\n",
    "        print(f\"{img_path}: {method}\")\n",
    "        if i == 2:\n",
    "            net = torch.hub.load(\"mhamilton723/FeatUp\", 'dinov2', use_norm=use_norm)\n",
    "            img_tensor = tensor.unsqueeze(0)\n",
    "        else:\n",
    "            net = HighResDV2(\"dino_vits8\", strides[i], dtype=torch.float16)\n",
    "            net.interpolation_mode = resizes[i]\n",
    "            if i == 3:\n",
    "                fwd_shift, inv_shift = tr.get_shift_transforms([1, 2,], 'Moore')\n",
    "                fwd_flip, inv_flip = tr.get_flip_transforms()\n",
    "                fwd, inv = tr.combine_transforms(fwd_shift, fwd_flip, inv_shift, inv_flip)\n",
    "                net.set_transforms(fwd, inv)\n",
    "            img_tensor = tensor\n",
    "        net.cuda()\n",
    "        net.eval()\n",
    "        feats_attn_tensor = net.forward(img_tensor)\n",
    "\n",
    "        if i == 2:\n",
    "            feats_attn_tensor = interpolate(feats_attn_tensor, (H, W))\n",
    "        print(feats_attn_tensor.shape)\n",
    "        pcaed = torch_pca(feats_attn_tensor.squeeze(0), 3, max_samples=80000)\n",
    "        pcaed = tr.to_numpy(pcaed)\n",
    "        rescaled = rescale_pca(pcaed)\n",
    "        out.append(rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling based comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_inset_zoom(xywh: list[int], fig_xywh: list[float], img_arr: np.ndarray, ax ) -> object:\n",
    "    x0, y0, w, h = xywh\n",
    "    fx, fy, fw, fh = fig_xywh\n",
    "    H, W, C = img_arr.shape\n",
    "    inset_data = np.zeros_like(img_arr)\n",
    "    inset_data[y0:y0+h, x0:x0+w, :] = img_arr[y0:y0+h, x0:x0+w, :]\n",
    "    extent = (0, H, W, 0)\n",
    "    # 418 / 518, 0 / 518, 150 / 518, 150 / 518\n",
    "    axin = ax.inset_axes(\n",
    "        fig_xywh, xlim=(x0, x0+w), ylim=(y0, y0+h))\n",
    "    axin.set_axis_off()\n",
    "    axin.imshow(inset_data)\n",
    "    ax.indicate_inset_zoom(axin, edgecolor=\"r\", lw=2)\n",
    "    axin.set_ylim((y0 + h, y0))\n",
    "    return axin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, axs = plt.subplots(len(img_paths), len(resizes) + 1)\n",
    "fig.set_size_inches(24, 8)\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "titles = [\"Low-Res (bilinear)\", \"Strided\", \"FeatUp (JBU)\", \"Ours (DINO-S-8)\"]\n",
    "#plt.suptitle(\"3 component PCAs\", fontsize=30)\n",
    "\n",
    "data_inset_locs = [[[150, 150, 70, 70], [350, 150, 70, 70]], [[150, 50, 70, 70], [360, 90, 70, 70]]]\n",
    "img_inset_locs = [[-0.1, 0.7, 0.4, 0.4], [0.8, 0.1, 0.4, 0.4]]\n",
    "\n",
    "i = 0\n",
    "for row, path in enumerate(img_paths):\n",
    "    fname = f\"fig_data/{path}.jpg\"\n",
    "    _, img_arr = load_img(fname)\n",
    "    H, W, C = img_arr.shape\n",
    "\n",
    "    img_ax = axs[row, 0]\n",
    "    img_ax.imshow(img_arr)\n",
    "\n",
    "    for inset_loc_idx in range(2):\n",
    "        x0, y0, w, h = data_inset_locs[row][inset_loc_idx]\n",
    "        add_inset_zoom([x0, y0, w, h], img_inset_locs[inset_loc_idx], img_arr, axs[row, 0])\n",
    "    axs[row, 0].set_axis_off()\n",
    "    if row == 0:\n",
    "        axs[row, 0].set_title(\"Image\", fontsize=26)\n",
    "\n",
    "    for column in range(0, len(resizes)):\n",
    "        ax = axs[row, column + 1]\n",
    "        data = out[i]\n",
    "\n",
    "        img = data.reshape((H, W, 3))\n",
    "        ax.imshow(img)\n",
    "        if row == 0:\n",
    "            ax.set_title(titles[column], fontsize=26)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        for inset_loc_idx in range(2):\n",
    "            x0, y0, w, h = data_inset_locs[row][inset_loc_idx]\n",
    "            add_inset_zoom([x0, y0, w, h], img_inset_locs[inset_loc_idx], img, ax)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_out/resolution_comparison.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
