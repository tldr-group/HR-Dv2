{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronan/HR-Dv2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import hr_dv2.transform as tr\n",
    "from hr_dv2.utils import *\n",
    "from hr_dv2 import HighResDV2\n",
    "from hr_dv2.high_res import torch_pca\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from featup.util import norm, unnorm\n",
    "use_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path: str, size: int=224) -> tuple[torch.Tensor, np.ndarray]:\n",
    "    _img = Image.open(path)\n",
    "    _h, _w = _img.height, _img.width\n",
    "    t = tr.get_input_transform(size, size)\n",
    "\n",
    "    img_tensor, img = tr.load_image(path, t)\n",
    "    img_arr = np.array(img)\n",
    "\n",
    "    img_tensor.to(torch.float16)\n",
    "    return img_tensor, img_arr\n",
    "\n",
    "def set_transforms(net: torch.nn.Module, d: int=3):\n",
    "    shift_dists = [i for i in range(1, d + 1)]\n",
    "    fwd_shift, inv_shift = tr.get_shift_transforms(shift_dists, 'Moore')\n",
    "    fwd_flip, inv_flip = tr.get_flip_transforms()\n",
    "    fwd, inv = tr.combine_transforms(fwd_shift, fwd_flip, inv_shift, inv_flip)\n",
    "    net.set_transforms(fwd_shift, inv_shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: dino_vits8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: dino_vits8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: dino_vits8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: dino_vits8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: dino_vits8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: dino_vits8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: dinov2_vits14_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/ronan/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: dinov2_vits14_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: dinov2_vits14_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: dinov2_vits14_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: dinov2_vits14_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: dinov2_vits14_reg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ronan/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 384\n",
    "out = []\n",
    "models = [\"dino_vits8\", \"dinov2_vits14_reg\"]\n",
    "fname = f\"fig_data/3.jpg\"\n",
    "strides = [0, 1, 2, 3, 4, 8]\n",
    "\n",
    "for model in models:\n",
    "    for i in strides:\n",
    "        print(f\"{i}: {model}\")\n",
    "        torch.cuda.empty_cache()\n",
    "        net = HighResDV2(model, 4, pca_dim=128, dtype=torch.float16)\n",
    "        net.interpolation_mode = 'nearest-exact'\n",
    "        net.cuda()\n",
    "        net.eval()\n",
    "\n",
    "        set_transforms(net, i)\n",
    "\n",
    "        size = 322\n",
    "        img_tensor, img_arr = load_img(fname, size)\n",
    "        img_tensor = img_tensor.cuda()\n",
    "\n",
    "        feats_attn_tensor = net.forward(img_tensor, attn_choice='none')\n",
    "        pcaed = torch_pca(feats_attn_tensor.squeeze(0), 3, max_samples=80000)\n",
    "        pcaed = tr.to_numpy(pcaed)\n",
    "        rescaled = rescale_pca(pcaed)\n",
    "        out.append(rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_inset_zoom(xywh: list[int], fig_xywh: list[float], img_arr: np.ndarray, ax ) -> object:\n",
    "    x0, y0, w, h = xywh\n",
    "    fx, fy, fw, fh = fig_xywh\n",
    "    H, W, C = img_arr.shape\n",
    "    inset_data = np.zeros_like(img_arr)\n",
    "    inset_data[y0:y0+h, x0:x0+w, :] = img_arr[y0:y0+h, x0:x0+w, :]\n",
    "    extent = (0, H, W, 0)\n",
    "    # 418 / 518, 0 / 518, 150 / 518, 150 / 518\n",
    "    axin = ax.inset_axes(\n",
    "        fig_xywh, xlim=(x0, x0+w), ylim=(y0, y0+h))\n",
    "    axin.set_axis_off()\n",
    "    axin.imshow(inset_data)\n",
    "    ax.indicate_inset_zoom(axin, edgecolor=\"r\", lw=2)\n",
    "    axin.set_ylim((y0 + h, y0))\n",
    "    return axin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, axs = plt.subplots(nrows=2, ncols=len(strides) + 1)\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "model_names = [\"DINO-S-8\", \"DINOv2-S-14\"]\n",
    "\n",
    "fig.set_size_inches(18, 8)\n",
    "i = 0\n",
    "font_size = 22\n",
    "for row in range(len(model_names)):\n",
    "    img = Image.open(f\"fig_data/3.jpg\")\n",
    "    axs[row, 0].imshow(img)\n",
    "    if row == 0:\n",
    "        axs[row, 0].set_title(\"Image\", fontsize=font_size)\n",
    "    axs[row, 0].set_ylabel(model_names[row], size=font_size)\n",
    "    axs[row, 0].set_xticks([])\n",
    "    axs[row, 0].set_yticks([])\n",
    "\n",
    "    add_inset_zoom([40, 200, 120, 120], [0.7, 0.7, 0.5, 0.5], np.array(img), axs[row, 0])\n",
    "\n",
    "    for column, s in enumerate(strides):\n",
    "        ax = axs[row, column + 1]\n",
    "        if row == 0:\n",
    "            print(column, model_names )\n",
    "            stride_txt = f\"{s}\" if s < 2 else f\"1-{s}\"\n",
    "            ax.set_title(f\"Shifts: {stride_txt}\", fontsize=font_size)\n",
    "\n",
    "        model = models[row]\n",
    "        size = 322 # if model != \"dinov2_vits14_reg\" else 378\n",
    "\n",
    "        data = out[i]\n",
    "        img = data.reshape((size, size, 3))\n",
    "        ax.imshow(img)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        add_inset_zoom([40, 200, 120, 120], [0.7, 0.7, 0.5, 0.5], img, ax)\n",
    "\n",
    "        i += 1\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_out/stride_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
